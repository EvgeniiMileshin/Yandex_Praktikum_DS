{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "# модели\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# чтение файла и печать общей информации\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получение первых 5 строк таблицы\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные уже подготовлены для работы с моделями. Нет пропусуов и дубликтов.\n",
    "\n",
    "Описание данных\n",
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Известно:\n",
    "- сalls — количество звонков,\n",
    "- minutes — суммарная длительность звонков в минутах,\n",
    "- messages — количество sms-сообщений,\n",
    "- mb_used — израсходованный интернет-трафик в Мб,\n",
    "- is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).\n",
    "\n",
    "Далее будет необходимо поделить данные на выборки и подготовить признаки для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разделение данных на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разделение на 2 выборки (обучающая и валидационная)\n",
    "df_train, df_valid = train_test_split(df, test_size=0.1, random_state=12345)\n",
    "\n",
    "# размер таблицы\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во строк в обучающей выборке: 2892\n",
      "Кол-во строк в валидационной выборке: 322\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во строк в обучающей выборке:', df_train.shape[0])\n",
    "print('Кол-во строк в валидационной выборке:', df_valid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во строк в обучающей выборке: 2570\n",
      "Кол-во строк в валидационной выборке: 322\n",
      "Кол-во строк в тестовой выборке: 322\n"
     ]
    }
   ],
   "source": [
    "# добавил 3ю выборку для теста, того же размера, что и валидационная\n",
    "df_test_size = df_valid.shape[0] / df_train.shape[0]\n",
    "df_train, df_test = train_test_split(df_train, test_size=df_test_size, random_state=12345)\n",
    "\n",
    "print('Кол-во строк в обучающей выборке:', df_train.shape[0])\n",
    "print('Кол-во строк в валидационной выборке:', df_valid.shape[0])\n",
    "print('Кол-во строк в тестовой выборке:', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидационная и тестовая выпорка имеют одинаковые пропорции по 10% от DF.\n",
    "\n",
    "Далее выделим целевой признак  и признаки для обучения модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на обучающие признаки и целевые\n",
    "\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе подготовили данные для обучения, проверки и тестирования моделей.\n",
    "\n",
    "Поделил Датасет на три выборки:\n",
    "\n",
    "- обучающая df_train,\n",
    "- валидационая df_valid,\n",
    "- тестовая df_test.\n",
    "\n",
    "Валидационная и тестовая выпорка имеют одинаковые пропорции по 10% от DF.\n",
    "\n",
    "Также, подготовили входные данные для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нами стоит задача классификации, поэтому проверим 3 модели:\n",
    "\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : \n",
      "Результат проверки на обучающей  выборке 0.7509727626459144\n",
      "Результат проверки на валидауионной выборке 0.7546583850931677\n",
      "\n",
      "max_depth = 2 : \n",
      "Результат проверки на обучающей  выборке 0.7817120622568093\n",
      "Результат проверки на валидауионной выборке 0.7763975155279503\n",
      "\n",
      "max_depth = 3 : \n",
      "Результат проверки на обучающей  выборке 0.7972762645914397\n",
      "Результат проверки на валидауионной выборке 0.7795031055900621\n",
      "\n",
      "max_depth = 4 : \n",
      "Результат проверки на обучающей  выборке 0.809727626459144\n",
      "Результат проверки на валидауионной выборке 0.7670807453416149\n",
      "\n",
      "max_depth = 5 : \n",
      "Результат проверки на обучающей  выборке 0.8202334630350194\n",
      "Результат проверки на валидауионной выборке 0.7701863354037267\n",
      "\n",
      "max_depth = 6 : \n",
      "Результат проверки на обучающей  выборке 0.8280155642023346\n",
      "Результат проверки на валидауионной выборке 0.7608695652173914\n",
      "\n",
      "max_depth = 7 : \n",
      "Результат проверки на обучающей  выборке 0.8455252918287938\n",
      "Результат проверки на валидауионной выборке 0.7701863354037267\n",
      "\n",
      "max_depth = 8 : \n",
      "Результат проверки на обучающей  выборке 0.8599221789883269\n",
      "Результат проверки на валидауионной выборке 0.7639751552795031\n",
      "\n",
      "max_depth = 9 : \n",
      "Результат проверки на обучающей  выборке 0.8700389105058366\n",
      "Результат проверки на валидауионной выборке 0.7670807453416149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# проведем перебор параметров и обучение модели с помледующей проверкой результатов\n",
    "for depth in range(1, 10):\n",
    "    model_DecisionTree = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_DecisionTree.fit(features_train, target_train)\n",
    "    predictions = model_DecisionTree.predict(features_train)\n",
    "    print(\"max_depth =\", depth, \": \")\n",
    "    print(\"Результат проверки на обучающей  выборке\", accuracy_score(target_train, predictions))\n",
    "    predictions = model_DecisionTree.predict(features_valid)\n",
    "    print(\"Результат проверки на валидауионной выборке\", accuracy_score(target_valid, predictions))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# авоматизизированный перебор параметрров для проверки результата с помощью GridSearchCV\n",
    "my_list = []\n",
    "for i in range(1, 500):\n",
    "    my_list.append(i)\n",
    "parameters = {'max_depth': my_list}\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=12345), \n",
    "                  parameters,\n",
    "                  scoring='accuracy')\n",
    "\n",
    "# обучение\n",
    "gs.fit(features_train, target_train)\n",
    "# просмотр лучших параметров\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лучший результат\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7701863354037267"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# настройка модели исходя из тестов\n",
    "model_DecisionTree = DecisionTreeClassifier(random_state=12345, max_depth=7)\n",
    "model_DecisionTree.fit(features_train, target_train)\n",
    "predictions_valid_DT = model_DecisionTree.predict(features_valid)\n",
    "accuracy_score(target_valid, predictions_valid_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ручной подбор параметров и GridSearchCV выявили что наилучший результат при max_depth = от 7 до 9.\n",
    "\n",
    "Выберем параметр 7, так как он показывает лучший результат на валидационной выборке 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 1 : \n",
      "Результат проверки на обучающей  выборке 0.9089494163424124\n",
      "Результат проверки на валидауионной выборке 0.7236024844720497\n",
      "\n",
      "n_estimators = 2 : \n",
      "Результат проверки на обучающей  выборке 0.909727626459144\n",
      "Результат проверки на валидауионной выборке 0.7515527950310559\n",
      "\n",
      "n_estimators = 3 : \n",
      "Результат проверки на обучающей  выборке 0.9529182879377431\n",
      "Результат проверки на валидауионной выборке 0.7515527950310559\n",
      "\n",
      "n_estimators = 4 : \n",
      "Результат проверки на обучающей  выборке 0.9521400778210116\n",
      "Результат проверки на валидауионной выборке 0.782608695652174\n",
      "\n",
      "n_estimators = 5 : \n",
      "Результат проверки на обучающей  выборке 0.9743190661478599\n",
      "Результат проверки на валидауионной выборке 0.7701863354037267\n",
      "\n",
      "n_estimators = 6 : \n",
      "Результат проверки на обучающей  выборке 0.9684824902723735\n",
      "Результат проверки на валидауионной выборке 0.7763975155279503\n",
      "\n",
      "n_estimators = 7 : \n",
      "Результат проверки на обучающей  выборке 0.9809338521400778\n",
      "Результат проверки на валидауионной выборке 0.7795031055900621\n",
      "\n",
      "n_estimators = 8 : \n",
      "Результат проверки на обучающей  выборке 0.9727626459143969\n",
      "Результат проверки на валидауионной выборке 0.7732919254658385\n",
      "\n",
      "n_estimators = 9 : \n",
      "Результат проверки на обучающей  выборке 0.9879377431906615\n",
      "Результат проверки на валидауионной выборке 0.7795031055900621\n",
      "\n",
      "n_estimators = 10 : \n",
      "Результат проверки на обучающей  выборке 0.9828793774319066\n",
      "Результат проверки на валидауионной выборке 0.7795031055900621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# проведем перебор параметров и обучение модели с помледующей проверкой результатов\n",
    "for estim in range(1, 11):\n",
    "    model_RandomForest = RandomForestClassifier(random_state=12345, n_estimators=estim)\n",
    "    model_RandomForest.fit(features_train, target_train)       \n",
    "    predictions = model_RandomForest.predict(features_train)\n",
    "    print(\"n_estimators =\", estim, \": \")\n",
    "    print(\"Результат проверки на обучающей  выборке\", accuracy_score(target_train, predictions))\n",
    "    predictions = model_RandomForest.predict(features_valid)\n",
    "    print(\"Результат проверки на валидауионной выборке\", accuracy_score(target_valid, predictions))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'n_estimators': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# авоматизизированный перебор параметрров для проверки результата с помощью GridSearchCV\n",
    "my_list = []\n",
    "for i in range(1, 20):\n",
    "    my_list.append(i)\n",
    "parameters = {'max_depth': [3, 4, 7],\n",
    "             'n_estimators' : my_list\n",
    "             }\n",
    "\n",
    "gs = GridSearchCV(RandomForestClassifier(random_state=12345), \n",
    "                  parameters,\n",
    "                  scoring='accuracy')\n",
    "\n",
    "# обучение\n",
    "gs.fit(features_train, target_train)\n",
    "# просмотр лучших параметров\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8062256809338522"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лучший результат\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888198757763976"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# настройка модели исходя из тестов\n",
    "model_RandomForest = RandomForestClassifier(random_state=12345, max_depth=7, n_estimators=4)\n",
    "model_RandomForest.fit(features_train, target_train)\n",
    "predictions_valid_RF = model_RandomForest.predict(features_valid)\n",
    "accuracy_score(target_valid, predictions_valid_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ручной подбор параметров и GridSearchCV выявили что наилучший результат при n_estimators = от 4 до 10.\n",
    "\n",
    "Выберем параметр 7, так как он показывает лучший результат на валидационной выборке 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7018633540372671"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogisticRegression = LogisticRegression(random_state=12345)\n",
    "model_LogisticRegression.fit(features_train, target_train)\n",
    "predictions_valid_LR = model_LogisticRegression.predict(features_valid)\n",
    "accuracy_score(target_valid, predictions_valid_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логическая регресия показывает результат 0,70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7950310559006211"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка рещуьтатов на тестовой выборке\n",
    "predictions_test_DT = model_DecisionTree.predict(features_test)\n",
    "accuracy_score(target_test, predictions_test_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167701863354038"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка рещуьтатов на тестовой выборке\n",
    "predictions_test_RF = model_RandomForest.predict(features_test)\n",
    "accuracy_score(target_test, predictions_test_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7018633540372671"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка рещуьтатов на тестовой выборке\n",
    "predictions_test_LR = model_LogisticRegression.predict(features_test)\n",
    "accuracy_score(target_test, predictions_test_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведя проверку модели на валидационно и тестовой выборке, лучший результат показвыаает модель RandomForest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на адекватность DummyClassifier \n",
    "dummy_clf =  DummyClassifier(strategy= \"most_frequent\") \n",
    "dummy_clf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111801242236024"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на валидационной выборке\n",
    "dummy_clf.score(features_valid,  target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на тестовой выборке\n",
    "dummy_clf.score(features_test,  target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на адекватность показала,что результат работы обченной модели лучше случайных результатов.\n",
    "\n",
    "Лучший результат показвыаает модель RandomForest рещультат на тестовой выборке 0.81, на валидационной 0,78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
